{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Project 2 - Recommender Systems - Surprise Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (implementations.py, line 76)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m2963\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-e1f490d8da7f>\"\u001b[1;36m, line \u001b[1;32m9\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from implementations import *\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\snrse\\Desktop\\FALL 2018-2019\\Machine Learning\\ML-Project-2-Rec-Sys\\implementations.py\"\u001b[1;36m, line \u001b[1;32m76\u001b[0m\n\u001b[1;33m    gs = GridSearchCV(algtype, param_grid, measures=['rmse'], cv=3)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from surprise import *\n",
    "from surprise.model_selection import PredefinedKFold\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "from implementations import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"data_train.csv\"\n",
    "submission_file = \"sampleSubmission.csv\"\n",
    "\n",
    "trainset, testset, df, toBeSubmitted = load_data(train_file, submission_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune HyperParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algtype = SVD\n",
    "param_grid = {'n_epochs': [30],\n",
    "              'lr_all': [0.01, 0.1],\n",
    "              'reg_all':[0.01, 0.1],\n",
    "             }\n",
    "gs = tuneHyperParams(algtype, trainset, testset, df, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('SVD.pkl', 'wb') as f:\n",
    "    pickle.dump(gs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algo = SVDpp(n_epochs=30,lr_all=0.001,reg_all=0.001)\n",
    "algo = SVD(n_epochs=1,lr_all=0.001,reg_all=0.001)\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "d = Dataset.load_from_df(df[['User', 'Movie', 'Rating']], reader)\n",
    "cross_validate(algo, d, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KnnBaseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune HyperParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algotype = KNNBaseline\n",
    "param_grid = {'k': [50, 300], 'n_epochs': [30],'name': ['pearson_baseline'], 'user_based': [True]}\n",
    "\n",
    "gs = tuneHyperParams(algotype, trainset, testset, df, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('knnUserBased.pkl', 'wb') as f:\n",
    "    pickle.dump(gs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algotype = KNNBaseline\n",
    "param_grid = {'k': [50, 300], 'n_epochs': [30],'name': ['pearson_baseline'], 'user_based': [False]}\n",
    "\n",
    "gs = tuneHyperParams(algotype, trainset, testset, df, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('knnItemBased.pkl', 'wb') as f:\n",
    "    pickle.dump(gs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsl_options = {'method': 'als','n_epochs': 20}\n",
    "sim_options = {'name': 'pearson_baseline'}\n",
    "algo = KNNBasic(k=300, bsl_options=bsl_options, sim_options=sim_options)\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "d = Dataset.load_from_df(df[['User', 'Movie', 'Rating']], reader)\n",
    "cross_validate(algo, d, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SlopeOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SlopeOne()\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "d = Dataset.load_from_df(df[['User', 'Movie', 'Rating']], reader)\n",
    "cross_validate(algo, d, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = BaselineOnly()\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "d = Dataset.load_from_df(df[['User', 'Movie', 'Rating']], reader)\n",
    "cross_validate(algo, d, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Algorithm\n",
    "#algo = SVDpp(n_epochs=30,lr_all=0.001,reg_all=0.001)\n",
    "algtype = SVD\n",
    "param_grid = {'n_epochs': [50],\n",
    "              'lr_all': [0.01, 0.0005, 0.001, 0.01, 0.1],\n",
    "              'reg_all':[0.01, 0.0005, 0.001, 0.01, 0.1],\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Hyperparameters via Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['User', 'Movie', 'Rating']], reader)\n",
    "#trainset, testset = train_test_split(data, test_size=.25, random_state=20)\n",
    "\n",
    "\n",
    "gs = GridSearchCV(algtype, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
    "\n",
    "model = gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "#algo = SVD(n_factors=factor ,n_epochs=epoch, lr_all=lr_rate, reg_all=reg_rate)\n",
    "algo = gs.best_estimator['rmse']\n",
    "\n",
    "model = algo.fit(trainset)\n",
    "\n",
    "# Predict\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Submission file\n",
    "create_submission_file('submission_surprise', predictions, toBeSubmitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runSlopeOne(trainset, testset, toBeSubmitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runBaselineOnly(trainset, testset, toBeSubmitted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
