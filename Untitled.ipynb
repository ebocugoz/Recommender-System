{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.linear_model import Ridge\n",
    "from glob import glob\n",
    "from surprise import Dataset, Reader\n",
    "import random\n",
    "from blend import *\n",
    "from implementations import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start spark context\n",
    "conf = (SparkConf().setMaster(\"local\").setAppName(\"My app\").set(\"spark.executor.memory\", \"1g\"))\n",
    "sc.stop()\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data sets...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data sets...\")\n",
    "data_train,data_test,data_actual_train,data_actual_predict = make_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS\n"
     ]
    }
   ],
   "source": [
    "als_predicts = pyspark_ALS(data_actual_train,data_actual_predict,sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"alsp_final.npy\",als_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = data_train.sample(frac=0.01, replace=True)\n",
    "data_test = data_test.sample(frac=0.01, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS\n"
     ]
    }
   ],
   "source": [
    "als_predicts = pyspark_ALS(data_train,data_test,sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions from each model...\n",
      "ALS\n",
      "Global Mean\n",
      "User Mean\n",
      "Item Mean\n",
      "MF SGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erdembocugoz/Desktop/University Documents/Githubs/ML-Project-2-Rec-Sys/matrix_fact_helpers.py:174: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  item_features[0, ind] = item_sum[ind, 0] / item_nnz[ind]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF ALS\n",
      "SVDpp\n",
      "pyfm\n",
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 0.84645\n",
      "-- Epoch 2\n",
      "Training MSE: 0.61830\n",
      "-- Epoch 3\n",
      "Training MSE: 0.60792\n",
      "-- Epoch 4\n",
      "Training MSE: 0.59799\n",
      "-- Epoch 5\n",
      "Training MSE: 0.58819\n",
      "-- Epoch 6\n",
      "Training MSE: 0.57910\n",
      "-- Epoch 7\n",
      "Training MSE: 0.57009\n",
      "-- Epoch 8\n",
      "Training MSE: 0.56288\n",
      "-- Epoch 9\n",
      "Training MSE: 0.55507\n",
      "-- Epoch 10\n",
      "Training MSE: 0.54750\n",
      "-- Epoch 11\n",
      "Training MSE: 0.54015\n",
      "-- Epoch 12\n",
      "Training MSE: 0.53335\n",
      "-- Epoch 13\n",
      "Training MSE: 0.52683\n",
      "-- Epoch 14\n",
      "Training MSE: 0.52003\n",
      "-- Epoch 15\n",
      "Training MSE: 0.51414\n",
      "-- Epoch 16\n",
      "Training MSE: 0.50830\n",
      "-- Epoch 17\n",
      "Training MSE: 0.50243\n",
      "-- Epoch 18\n",
      "Training MSE: 0.49681\n",
      "-- Epoch 19\n",
      "Training MSE: 0.49185\n",
      "-- Epoch 20\n",
      "Training MSE: 0.48633\n",
      "-- Epoch 21\n",
      "Training MSE: 0.48143\n",
      "-- Epoch 22\n",
      "Training MSE: 0.47666\n",
      "-- Epoch 23\n",
      "Training MSE: 0.47186\n",
      "-- Epoch 24\n",
      "Training MSE: 0.46737\n",
      "-- Epoch 25\n",
      "Training MSE: 0.46283\n",
      "-- Epoch 26\n",
      "Training MSE: 0.45863\n",
      "-- Epoch 27\n",
      "Training MSE: 0.45434\n",
      "-- Epoch 28\n",
      "Training MSE: 0.45019\n",
      "-- Epoch 29\n",
      "Training MSE: 0.44586\n",
      "-- Epoch 30\n",
      "Training MSE: 0.44203\n",
      "-- Epoch 31\n",
      "Training MSE: 0.43810\n",
      "-- Epoch 32\n",
      "Training MSE: 0.43466\n",
      "-- Epoch 33\n",
      "Training MSE: 0.43100\n",
      "-- Epoch 34\n",
      "Training MSE: 0.42723\n",
      "-- Epoch 35\n",
      "Training MSE: 0.42380\n",
      "-- Epoch 36\n",
      "Training MSE: 0.42020\n",
      "-- Epoch 37\n",
      "Training MSE: 0.41700\n",
      "-- Epoch 38\n",
      "Training MSE: 0.41347\n",
      "-- Epoch 39\n",
      "Training MSE: 0.41041\n",
      "-- Epoch 40\n",
      "Training MSE: 0.40722\n",
      "-- Epoch 41\n",
      "Training MSE: 0.40384\n",
      "-- Epoch 42\n",
      "Training MSE: 0.40076\n",
      "-- Epoch 43\n",
      "Training MSE: 0.39753\n",
      "-- Epoch 44\n",
      "Training MSE: 0.39468\n",
      "-- Epoch 45\n",
      "Training MSE: 0.39204\n",
      "-- Epoch 46\n",
      "Training MSE: 0.38912\n",
      "-- Epoch 47\n",
      "Training MSE: 0.38589\n",
      "-- Epoch 48\n",
      "Training MSE: 0.38332\n",
      "-- Epoch 49\n",
      "Training MSE: 0.38052\n",
      "-- Epoch 50\n",
      "Training MSE: 0.37787\n",
      "-- Epoch 51\n",
      "Training MSE: 0.37500\n",
      "-- Epoch 52\n",
      "Training MSE: 0.37233\n",
      "-- Epoch 53\n",
      "Training MSE: 0.36977\n",
      "-- Epoch 54\n",
      "Training MSE: 0.36732\n",
      "-- Epoch 55\n",
      "Training MSE: 0.36477\n",
      "-- Epoch 56\n",
      "Training MSE: 0.36213\n",
      "-- Epoch 57\n",
      "Training MSE: 0.35966\n",
      "-- Epoch 58\n",
      "Training MSE: 0.35722\n",
      "-- Epoch 59\n",
      "Training MSE: 0.35474\n",
      "-- Epoch 60\n",
      "Training MSE: 0.35232\n",
      "-- Epoch 61\n",
      "Training MSE: 0.34979\n",
      "-- Epoch 62\n",
      "Training MSE: 0.34738\n",
      "-- Epoch 63\n",
      "Training MSE: 0.34517\n",
      "-- Epoch 64\n",
      "Training MSE: 0.34260\n",
      "-- Epoch 65\n",
      "Training MSE: 0.34055\n",
      "-- Epoch 66\n",
      "Training MSE: 0.33827\n",
      "-- Epoch 67\n",
      "Training MSE: 0.33589\n",
      "-- Epoch 68\n",
      "Training MSE: 0.33371\n",
      "-- Epoch 69\n",
      "Training MSE: 0.33139\n",
      "-- Epoch 70\n",
      "Training MSE: 0.32917\n",
      "-- Epoch 71\n",
      "Training MSE: 0.32707\n",
      "-- Epoch 72\n",
      "Training MSE: 0.32494\n",
      "-- Epoch 73\n",
      "Training MSE: 0.32274\n",
      "-- Epoch 74\n",
      "Training MSE: 0.32074\n",
      "-- Epoch 75\n",
      "Training MSE: 0.31860\n",
      "-- Epoch 76\n",
      "Training MSE: 0.31641\n",
      "-- Epoch 77\n",
      "Training MSE: 0.31437\n",
      "-- Epoch 78\n",
      "Training MSE: 0.31228\n",
      "-- Epoch 79\n",
      "Training MSE: 0.30999\n",
      "-- Epoch 80\n",
      "Training MSE: 0.30802\n",
      "-- Epoch 81\n",
      "Training MSE: 0.30603\n",
      "-- Epoch 82\n",
      "Training MSE: 0.30425\n",
      "-- Epoch 83\n",
      "Training MSE: 0.30229\n",
      "-- Epoch 84\n",
      "Training MSE: 0.30005\n",
      "-- Epoch 85\n",
      "Training MSE: 0.29805\n",
      "-- Epoch 86\n",
      "Training MSE: 0.29614\n",
      "-- Epoch 87\n",
      "Training MSE: 0.29439\n",
      "-- Epoch 88\n",
      "Training MSE: 0.29197\n",
      "-- Epoch 89\n",
      "Training MSE: 0.29029\n",
      "-- Epoch 90\n",
      "Training MSE: 0.28855\n",
      "-- Epoch 91\n",
      "Training MSE: 0.28676\n",
      "-- Epoch 92\n",
      "Training MSE: 0.28470\n",
      "-- Epoch 93\n",
      "Training MSE: 0.28262\n",
      "-- Epoch 94\n",
      "Training MSE: 0.28093\n",
      "-- Epoch 95\n",
      "Training MSE: 0.27918\n",
      "-- Epoch 96\n",
      "Training MSE: 0.27732\n",
      "-- Epoch 97\n",
      "Training MSE: 0.27549\n",
      "-- Epoch 98\n",
      "Training MSE: 0.27363\n",
      "-- Epoch 99\n",
      "Training MSE: 0.27169\n",
      "-- Epoch 100\n",
      "Training MSE: 0.26999\n",
      "-- Epoch 101\n",
      "Training MSE: 0.26823\n",
      "-- Epoch 102\n",
      "Training MSE: 0.26650\n",
      "-- Epoch 103\n",
      "Training MSE: 0.26437\n",
      "-- Epoch 104\n",
      "Training MSE: 0.26290\n",
      "-- Epoch 105\n",
      "Training MSE: 0.26120\n",
      "-- Epoch 106\n",
      "Training MSE: 0.25941\n",
      "-- Epoch 107\n",
      "Training MSE: 0.25763\n",
      "-- Epoch 108\n",
      "Training MSE: 0.25591\n",
      "-- Epoch 109\n",
      "Training MSE: 0.25420\n",
      "-- Epoch 110\n",
      "Training MSE: 0.25241\n",
      "-- Epoch 111\n",
      "Training MSE: 0.25051\n",
      "-- Epoch 112\n",
      "Training MSE: 0.24900\n",
      "-- Epoch 113\n",
      "Training MSE: 0.24737\n",
      "-- Epoch 114\n",
      "Training MSE: 0.24568\n",
      "-- Epoch 115\n",
      "Training MSE: 0.24392\n",
      "-- Epoch 116\n",
      "Training MSE: 0.24227\n",
      "-- Epoch 117\n",
      "Training MSE: 0.24074\n",
      "-- Epoch 118\n",
      "Training MSE: 0.23902\n",
      "-- Epoch 119\n",
      "Training MSE: 0.23720\n",
      "-- Epoch 120\n",
      "Training MSE: 0.23558\n",
      "-- Epoch 121\n",
      "Training MSE: 0.23409\n",
      "-- Epoch 122\n",
      "Training MSE: 0.23244\n",
      "-- Epoch 123\n",
      "Training MSE: 0.23075\n",
      "-- Epoch 124\n",
      "Training MSE: 0.22925\n",
      "-- Epoch 125\n",
      "Training MSE: 0.22751\n",
      "-- Epoch 126\n",
      "Training MSE: 0.22588\n",
      "-- Epoch 127\n",
      "Training MSE: 0.22444\n",
      "-- Epoch 128\n",
      "Training MSE: 0.22270\n",
      "-- Epoch 129\n",
      "Training MSE: 0.22121\n",
      "-- Epoch 130\n",
      "Training MSE: 0.21967\n",
      "-- Epoch 131\n",
      "Training MSE: 0.21806\n",
      "-- Epoch 132\n",
      "Training MSE: 0.21653\n",
      "-- Epoch 133\n",
      "Training MSE: 0.21498\n",
      "-- Epoch 134\n",
      "Training MSE: 0.21339\n",
      "-- Epoch 135\n",
      "Training MSE: 0.21193\n",
      "-- Epoch 136\n",
      "Training MSE: 0.21033\n",
      "-- Epoch 137\n",
      "Training MSE: 0.20884\n",
      "-- Epoch 138\n",
      "Training MSE: 0.20725\n",
      "-- Epoch 139\n",
      "Training MSE: 0.20575\n",
      "-- Epoch 140\n",
      "Training MSE: 0.20420\n",
      "-- Epoch 141\n",
      "Training MSE: 0.20284\n",
      "-- Epoch 142\n",
      "Training MSE: 0.20123\n",
      "-- Epoch 143\n",
      "Training MSE: 0.19985\n",
      "-- Epoch 144\n",
      "Training MSE: 0.19829\n",
      "-- Epoch 145\n",
      "Training MSE: 0.19685\n",
      "-- Epoch 146\n",
      "Training MSE: 0.19545\n",
      "-- Epoch 147\n",
      "Training MSE: 0.19377\n",
      "-- Epoch 148\n",
      "Training MSE: 0.19248\n",
      "-- Epoch 149\n",
      "Training MSE: 0.19109\n",
      "-- Epoch 150\n",
      "Training MSE: 0.18962\n",
      "-- Epoch 151\n",
      "Training MSE: 0.18820\n",
      "-- Epoch 152\n",
      "Training MSE: 0.18683\n",
      "-- Epoch 153\n",
      "Training MSE: 0.18538\n",
      "-- Epoch 154\n",
      "Training MSE: 0.18391\n",
      "-- Epoch 155\n",
      "Training MSE: 0.18242\n",
      "-- Epoch 156\n",
      "Training MSE: 0.18119\n",
      "-- Epoch 157\n",
      "Training MSE: 0.17980\n",
      "-- Epoch 158\n",
      "Training MSE: 0.17839\n",
      "-- Epoch 159\n",
      "Training MSE: 0.17707\n",
      "-- Epoch 160\n",
      "Training MSE: 0.17566\n",
      "-- Epoch 161\n",
      "Training MSE: 0.17433\n",
      "-- Epoch 162\n",
      "Training MSE: 0.17293\n",
      "-- Epoch 163\n",
      "Training MSE: 0.17148\n",
      "-- Epoch 164\n",
      "Training MSE: 0.17029\n",
      "-- Epoch 165\n",
      "Training MSE: 0.16894\n",
      "-- Epoch 166\n",
      "Training MSE: 0.16762\n",
      "-- Epoch 167\n",
      "Training MSE: 0.16620\n",
      "-- Epoch 168\n",
      "Training MSE: 0.16494\n",
      "-- Epoch 169\n",
      "Training MSE: 0.16369\n",
      "-- Epoch 170\n",
      "Training MSE: 0.16238\n",
      "-- Epoch 171\n",
      "Training MSE: 0.16110\n",
      "-- Epoch 172\n",
      "Training MSE: 0.15987\n",
      "-- Epoch 173\n",
      "Training MSE: 0.15855\n",
      "-- Epoch 174\n",
      "Training MSE: 0.15732\n",
      "-- Epoch 175\n",
      "Training MSE: 0.15610\n",
      "-- Epoch 176\n",
      "Training MSE: 0.15477\n",
      "-- Epoch 177\n",
      "Training MSE: 0.15360\n",
      "-- Epoch 178\n",
      "Training MSE: 0.15233\n",
      "-- Epoch 179\n",
      "Training MSE: 0.15113\n",
      "-- Epoch 180\n",
      "Training MSE: 0.14986\n",
      "-- Epoch 181\n",
      "Training MSE: 0.14871\n",
      "-- Epoch 182\n",
      "Training MSE: 0.14745\n",
      "-- Epoch 183\n",
      "Training MSE: 0.14625\n",
      "-- Epoch 184\n",
      "Training MSE: 0.14500\n",
      "-- Epoch 185\n",
      "Training MSE: 0.14391\n",
      "-- Epoch 186\n",
      "Training MSE: 0.14272\n",
      "-- Epoch 187\n",
      "Training MSE: 0.14160\n",
      "-- Epoch 188\n",
      "Training MSE: 0.14042\n",
      "-- Epoch 189\n",
      "Training MSE: 0.13927\n",
      "-- Epoch 190\n",
      "Training MSE: 0.13808\n",
      "-- Epoch 191\n",
      "Training MSE: 0.13693\n",
      "-- Epoch 192\n",
      "Training MSE: 0.13586\n",
      "-- Epoch 193\n",
      "Training MSE: 0.13475\n",
      "-- Epoch 194\n",
      "Training MSE: 0.13362\n",
      "-- Epoch 195\n",
      "Training MSE: 0.13256\n",
      "-- Epoch 196\n",
      "Training MSE: 0.13147\n",
      "-- Epoch 197\n",
      "Training MSE: 0.13032\n",
      "-- Epoch 198\n",
      "Training MSE: 0.12924\n",
      "-- Epoch 199\n",
      "Training MSE: 0.12817\n",
      "-- Epoch 200\n",
      "Training MSE: 0.12706\n",
      "baseline\n",
      "Estimating biases using als...\n",
      "slopeone\n",
      "knnUB\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "knnIB\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "SVD\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting predictions from each model...\")\n",
    "all_predicts = get_predicts(data_train,data_test,sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = data_test[\"Rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3884,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2305,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_predicts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2305,) (3884,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-cc51af7bb68e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcalculate_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_predicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/University Documents/Githubs/ML-Project-2-Rec-Sys/blend.py\u001b[0m in \u001b[0;36mcalculate_rmse\u001b[0;34m(real_labels, predictions)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;34m\"\"\"Calculate RMSE.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_labels\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2305,) (3884,) "
     ]
    }
   ],
   "source": [
    "\n",
    "calculate_rmse(all_predicts[6],target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Loading pre trained Ridge Regression Function for blending models...\")\n",
    "#Load predefined regression function for blending\n",
    "with open(r\"linreg.pkl\", \"rb\") as input_file:\n",
    "    linreg = pickle.load(input_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Blending...\")\n",
    "#Blend models\n",
    "final_predictions = linreg.predict(all_predicts.T)\n",
    "final_predictions = np.clip(final_predictions, 1, 5)\n",
    "final_predictions = np.round(final_predictions)\n",
    "\n",
    "data_actual_predict[\"Rating\"] = final_predictions\n",
    "print(\"Creating submission file\")\n",
    "submission = submission_table(data_actual_predict, 'User', 'Movie', 'Rating')\n",
    "\n",
    "\n",
    "file_name = 'submission.csv'\n",
    "submission.to_csv(file_name, index=False)\n",
    "\n",
    "print(\"Submission file created\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
