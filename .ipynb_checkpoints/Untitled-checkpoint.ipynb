{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import *\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Dataset.load_builtin('ml-100k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algo = SVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.raw_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['User'] = df['Id'].apply(lambda x: int(x.split('_')[0][1:]))\n",
    "df['Movie'] = df['Id'].apply(lambda x: int(x.split('_')[1][1:]))\n",
    "df['Rating'] = df['Prediction']\n",
    "df = df.drop(['Id', 'Prediction'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'tmp_train.csv'\n",
    "header = ['user_id','item_id','rating']\n",
    "df.to_csv(train_file, index=False, header=False)\n",
    "ratings_df = pd.read_csv('tmp_train.csv',\n",
    "                          sep=',',\n",
    "                         names=header,\n",
    "                         \n",
    "                         dtype={\n",
    "                           'user_id': np.int32,\n",
    "                           'item_id': np.int32,\n",
    "                           'rating': np.float32,\n",
    "                           'timestamp': np.int32,\n",
    "                         })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>310</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>318</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>355</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>390</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>401</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>410</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>418</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>457</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>470</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>497</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>566</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>595</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>670</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>673</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176922</th>\n",
       "      <td>9846</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176923</th>\n",
       "      <td>9855</td>\n",
       "      <td>1000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176924</th>\n",
       "      <td>9867</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176925</th>\n",
       "      <td>9874</td>\n",
       "      <td>1000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176926</th>\n",
       "      <td>9875</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176927</th>\n",
       "      <td>9884</td>\n",
       "      <td>1000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176928</th>\n",
       "      <td>9890</td>\n",
       "      <td>1000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176929</th>\n",
       "      <td>9904</td>\n",
       "      <td>1000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176930</th>\n",
       "      <td>9909</td>\n",
       "      <td>1000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176931</th>\n",
       "      <td>9913</td>\n",
       "      <td>1000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176932</th>\n",
       "      <td>9922</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176933</th>\n",
       "      <td>9925</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176934</th>\n",
       "      <td>9929</td>\n",
       "      <td>1000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176935</th>\n",
       "      <td>9936</td>\n",
       "      <td>1000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176936</th>\n",
       "      <td>9944</td>\n",
       "      <td>1000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176937</th>\n",
       "      <td>9945</td>\n",
       "      <td>1000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176938</th>\n",
       "      <td>9949</td>\n",
       "      <td>1000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176939</th>\n",
       "      <td>9957</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176940</th>\n",
       "      <td>9958</td>\n",
       "      <td>1000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176941</th>\n",
       "      <td>9960</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176942</th>\n",
       "      <td>9961</td>\n",
       "      <td>1000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176943</th>\n",
       "      <td>9964</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176944</th>\n",
       "      <td>9968</td>\n",
       "      <td>1000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176945</th>\n",
       "      <td>9970</td>\n",
       "      <td>1000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176946</th>\n",
       "      <td>9976</td>\n",
       "      <td>1000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176947</th>\n",
       "      <td>9990</td>\n",
       "      <td>1000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176948</th>\n",
       "      <td>9992</td>\n",
       "      <td>1000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176949</th>\n",
       "      <td>9994</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176950</th>\n",
       "      <td>9997</td>\n",
       "      <td>1000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176951</th>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176952 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  rating\n",
       "0             44        1     4.0\n",
       "1             61        1     3.0\n",
       "2             67        1     4.0\n",
       "3             72        1     3.0\n",
       "4             86        1     5.0\n",
       "5             90        1     4.0\n",
       "6            108        1     3.0\n",
       "7            114        1     3.0\n",
       "8            120        1     2.0\n",
       "9            135        1     5.0\n",
       "10           152        1     4.0\n",
       "11           165        1     3.0\n",
       "12           182        1     3.0\n",
       "13           310        1     3.0\n",
       "14           318        1     1.0\n",
       "15           333        1     3.0\n",
       "16           355        1     2.0\n",
       "17           390        1     4.0\n",
       "18           401        1     4.0\n",
       "19           410        1     2.0\n",
       "20           418        1     3.0\n",
       "21           457        1     2.0\n",
       "22           470        1     4.0\n",
       "23           497        1     3.0\n",
       "24           516        1     3.0\n",
       "25           566        1     3.0\n",
       "26           595        1     2.0\n",
       "27           670        1     3.0\n",
       "28           673        1     4.0\n",
       "29           708        1     1.0\n",
       "...          ...      ...     ...\n",
       "1176922     9846     1000     3.0\n",
       "1176923     9855     1000     4.0\n",
       "1176924     9867     1000     3.0\n",
       "1176925     9874     1000     5.0\n",
       "1176926     9875     1000     3.0\n",
       "1176927     9884     1000     2.0\n",
       "1176928     9890     1000     5.0\n",
       "1176929     9904     1000     5.0\n",
       "1176930     9909     1000     4.0\n",
       "1176931     9913     1000     2.0\n",
       "1176932     9922     1000     3.0\n",
       "1176933     9925     1000     3.0\n",
       "1176934     9929     1000     4.0\n",
       "1176935     9936     1000     2.0\n",
       "1176936     9944     1000     4.0\n",
       "1176937     9945     1000     5.0\n",
       "1176938     9949     1000     4.0\n",
       "1176939     9957     1000     3.0\n",
       "1176940     9958     1000     4.0\n",
       "1176941     9960     1000     3.0\n",
       "1176942     9961     1000     4.0\n",
       "1176943     9964     1000     3.0\n",
       "1176944     9968     1000     5.0\n",
       "1176945     9970     1000     5.0\n",
       "1176946     9976     1000     5.0\n",
       "1176947     9990     1000     4.0\n",
       "1176948     9992     1000     5.0\n",
       "1176949     9994     1000     3.0\n",
       "1176950     9997     1000     4.0\n",
       "1176951    10000     1000     3.0\n",
       "\n",
       "[1176952 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-49178637930c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Train and test set for Surprise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_file' is not defined"
     ]
    }
   ],
   "source": [
    "reader = Reader(line_format='user item rating', sep=',')\n",
    "\n",
    "# Train and test set for Surprise\n",
    "# Load the data\n",
    "data = Dataset.load_from_file(train_file, reader=reader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Algorithm\n",
    "cross_validate(BaselineOnly(), data, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.01475573215\n",
      "{'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.4}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.0137  1.0160  1.0150  1.0149  0.0009  \n",
      "MAE (testset)     0.8329  0.8345  0.8338  0.8338  0.0007  \n",
      "Fit time          27.90   28.24   28.08   28.08   0.14    \n",
      "Test time         4.02    4.08    4.24    4.11    0.09    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': (27.902974843978882, 28.242528915405273, 28.08003878593445),\n",
       " 'test_mae': array([ 0.8329248 ,  0.83454309,  0.83379876]),\n",
       " 'test_rmse': array([ 1.01371165,  1.01601206,  1.01498273]),\n",
       " 'test_time': (4.022264003753662, 4.077057838439941, 4.2442100048065186)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(SVD(n_epochs=10,lr_all=0.002,reg_all=0.4), data, verbose=True,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    0.9994  1.0012  1.0001  1.0002  0.0007  \n",
      "MAE (testset)     0.8053  0.8068  0.8057  0.8060  0.0006  \n",
      "Fit time          2.38    2.75    2.76    2.63    0.17    \n",
      "Test time         4.33    4.15    3.72    4.06    0.26    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': (2.384819984436035, 2.7514288425445557, 2.758358955383301),\n",
       " 'test_mae': array([ 0.80532221,  0.80683905,  0.80573148]),\n",
       " 'test_rmse': array([ 0.99935076,  1.00115189,  1.00005555]),\n",
       " 'test_time': (4.326732873916626, 4.1499340534210205, 3.7171547412872314)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(BaselineOnly(), data, verbose=True,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import user_based_train_test_split\n",
    "from spotlight.datasets.synthetic import generate_sequential\n",
    "from spotlight.evaluation import sequence_mrr_score\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = generate_sequential(num_users=100,\n",
    "                              num_items=1000,\n",
    "                              num_interactions=10000,\n",
    "                              concentration_parameter=0.01,\n",
    "                              order=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Interactions dataset (100 users x 1000 items x 10000 interactions)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "dataset = get_movielens_dataset(variant='100K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([881250949, 891717742, 878887116, ..., 874795795, 882399156,\n",
       "       879959583], dtype=int32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spotlight.datasets import _transport\n",
    "from spotlight.interactions import Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userid = df.values[:,0].astype(np.int32)\n",
    "movieid = df.values[:,1].astype(np.int32)\n",
    "rating = df.values[:,2].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = Interactions(userid,movieid,rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert to sequences, timestamps not available.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-51acdbf74a03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_based_train_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/spotlight/interactions.py\u001b[0m in \u001b[0;36mto_sequence\u001b[0;34m(self, max_sequence_length, min_sequence_length, step_size)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             raise ValueError('Cannot convert to sequences, '\n\u001b[0m\u001b[1;32m    224\u001b[0m                              'timestamps not available.')\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert to sequences, timestamps not available."
     ]
    }
   ],
   "source": [
    "train, test = user_based_train_test_split(dataset)\n",
    "\n",
    "train = train.to_sequence()\n",
    "test = test.to_sequence()\n",
    "\n",
    "model = ImplicitSequenceModel(n_iter=3,\n",
    "                              representation='cnn',\n",
    "                              loss='bpr')\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['User'] = df['Id'].apply(lambda x: int(x.split('_')[0][1:]))\n",
    "df['Movie'] = df['Id'].apply(lambda x: int(x.split('_')[1][1:]))\n",
    "df['Rating'] = df['Prediction']\n",
    "df = df.drop(['Id', 'Prediction'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = 'tmp_train.csv'\n",
    "header = ['user_id','item_id','rating']\n",
    "df.to_csv(train_file, index=False, header=False)\n",
    "ratings_df = pd.read_csv('tmp_train.csv',\n",
    "                          sep=',',\n",
    "                         names=header,\n",
    "                         \n",
    "                         dtype={\n",
    "                           'user_id': np.int32,\n",
    "                           'item_id': np.int32,\n",
    "                           'rating': np.float32,\n",
    "                           'timestamp': np.int32,\n",
    "                         })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erdembocugoz/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "ratings = ratings_df.as_matrix(['user_id', 'item_id', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings[:,0] -= 1\n",
    "ratings[:,1] -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 1m and 20m MovieLens datasets skip some user and item IDs. This creates a problem: you have to map the set of unique user IDs to an index set equal to [0 ... num_users-1] and do the same for item IDs. The item mapping is accomplished using the following [numpy](http://www.numpy.org/) code. The code creates an array of size [0..max_item_id] to perform the mapping, so if the maximum item ID is very large, this method might use too much memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erdembocugoz/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "np_items = ratings_df.item_id.as_matrix()\n",
    "unique_items = np.unique(np_items)\n",
    "n_items = unique_items.shape[0]\n",
    "max_item = unique_items[-1]\n",
    "\n",
    "# map unique items down to an array 0..n_items-1\n",
    "z = np.zeros(max_item+1, dtype=int)\n",
    "z[unique_items] = np.arange(n_items)\n",
    "i_r = z[np_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erdembocugoz/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "np_users = ratings_df.user_id.as_matrix()\n",
    "unique_users = np.unique(np_users)\n",
    "n_users = unique_users.shape[0]\n",
    "max_user = unique_users[-1]\n",
    "\n",
    "# map unique items down to an array 0..n_items-1\n",
    "z = np.zeros(max_user+1, dtype=int)\n",
    "z[unique_users] = np.arange(n_users)\n",
    "i_r = z[np_users]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### The model code randomly selects a test set of ratings. By default, 10% of the ratings are chosen for the test set. These ratings are removed from the training set and will be used to evaluate the predictive accuracy of the user and item factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_size = int(len(ratings) / 10)\n",
    "test_set_idx = np.random.choice(range(len(ratings)),\n",
    "                                size=test_set_size, replace=False)\n",
    "test_set_idx = sorted(test_set_idx)\n",
    "\n",
    "ts_ratings = ratings[test_set_idx]\n",
    "tr_ratings = np.delete(ratings, test_set_idx, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, the code creates a scipy sparse matrix in coordinate form (coo_matrix) that includes the user and item indexes and ratings. The coo_matrix object acts as a wrapper for a sparse matrix. It also performs validation of the user and ratings indexes, checking for errors in preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "u_tr, i_tr, r_tr = zip(*tr_ratings)\n",
    "u_te, i_te, r_te= zip(*ts_ratings)\n",
    "tr_sparse = coo_matrix((r_tr, (u_tr, i_tr)), shape=(n_users, n_items))\n",
    "te_sparse = coo_matrix((r_te, (u_te, i_te)), shape=(n_users, n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1059257 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Weighted Alternating Squares method by using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indice = list(zip(tr_sparse.row, tr_sparse.col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_wts(data, wt_type, obs_wt, feature_wt_exp, axis):\n",
    "    \"\"\"Generate observed item weights.\n",
    "    Args:\n",
    "    data:             coo_matrix of ratings data\n",
    "    wt_type:          weight type, LOG_RATINGS or LINEAR_RATINGS\n",
    "    obs_wt:           linear weight factor\n",
    "    feature_wt_exp:   logarithmic weight factor\n",
    "    axis:             axis to make weights for, 1=rows/users, 0=cols/items\n",
    "    Returns:\n",
    "    vector of weights for cols (items) or rows (users)\n",
    "    \"\"\"\n",
    "    # recipricol of sum of number of items across rows (if axis is 0)\n",
    "    frac = np.array(1.0/(data > 0.0).sum(axis))\n",
    "\n",
    "    # filter any invalid entries\n",
    "    frac[np.ma.masked_invalid(frac).mask] = 0.0\n",
    "\n",
    "    # normalize weights according to assumed distribution of ratings\n",
    "    if wt_type == \"LOG_RATINGS\":\n",
    "        wts = np.array(np.power(frac, feature_wt_exp)).flatten()\n",
    "    else:\n",
    "        wts = np.array(obs_wt * frac).flatten()\n",
    "\n",
    "    # check again for any numerically unstable entries\n",
    "    assert np.isfinite(wts).sum() == wts.shape[0]\n",
    "    return wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 34\n",
    "num_iters = 20\n",
    "reg = 9.83\n",
    "unobs = 0.001\n",
    "wt_type = 1\n",
    "feature_wt_factor =  189.8\n",
    "obs_wt = 100\n",
    "num_rows = tr_sparse.shape[0]\n",
    "num_cols = tr_sparse.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Note that data is sparse matrix created by coo_matrix\n",
    "input_tensor = tf.SparseTensor(indices=indice,\n",
    "                                values=(tr_sparse.data).astype(np.float32),\n",
    "                                dense_shape=tr_sparse.shape)\n",
    "assert feature_wt_exp is not None\n",
    "row_wts = np.ones(num_rows)\n",
    "col_wts = make_wts(tr_sparse, \"LINEAR_RATINGS\", feature_wt_factor , None, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  tf.contrib.factorization.WALSModel(num_rows, num_cols, dim,\n",
    "                                    unobserved_weight=unobs,\n",
    "                                    regularization=reg,\n",
    "                                    row_weights=row_wts,\n",
    "                                    col_weights=col_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retrieve the row and column factors\n",
    "row_factor = model.row_factors[0]\n",
    "col_factor = model.col_factors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_update_op = model.update_row_factors(sp_input=input_tensor)[1]\n",
    "col_update_op = model.update_col_factors(sp_input=input_tensor)[1]\n",
    "sess = tf.Session(graph=input_tensor.graph)\n",
    "sess.run(model.initialize_op)\n",
    "sess.run(model.worker_init)\n",
    "for _ in range(num_iters):\n",
    "    sess.run(model.row_update_prep_gramian_op)\n",
    "    sess.run(model.initialize_row_update_op)\n",
    "    sess.run(row_update_op)\n",
    "    sess.run(model.col_update_prep_gramian_op)\n",
    "    sess.run(model.initialize_col_update_op)\n",
    "    sess.run(col_update_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate output factor matrices\n",
    "output_row = row_factor.eval(session=sess)\n",
    "output_col = col_factor.eval(session=sess)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rmse(output_row, output_col, actual):\n",
    "    \"\"\"Compute rmse between predicted and actual ratings.\n",
    "      Args:\n",
    "        output_row: evaluated numpy array of row_factor\n",
    "        output_col: evaluated numpy array of col_factor\n",
    "        actual: coo_matrix of actual (test) values\n",
    "      Returns:\n",
    "        rmse\n",
    "      \"\"\"\n",
    "    mse = 0\n",
    "    for i in range(actual.data.shape[0]):\n",
    "        row_pred = output_row[actual.row[i]]\n",
    "        col_pred = output_col[actual.col[i]]\n",
    "        err = actual.data[i] - np.dot(row_pred, col_pred)\n",
    "        mse += err * err\n",
    "    mse /= actual.data.shape[0]\n",
    "    rmse = math.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0287926964239236"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " get_rmse(output_row, output_col, te_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erdembocugoz/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_wts(data, wt_type, obs_wt, feature_wt_exp, axis):\n",
    "    \"\"\"Generate observed item weights.\n",
    "    Args:\n",
    "    data:             coo_matrix of ratings data\n",
    "    wt_type:          weight type, LOG_RATINGS or LINEAR_RATINGS\n",
    "    obs_wt:           linear weight factor\n",
    "    feature_wt_exp:   logarithmic weight factor\n",
    "    axis:             axis to make weights for, 1=rows/users, 0=cols/items\n",
    "    Returns:\n",
    "    vector of weights for cols (items) or rows (users)\n",
    "    \"\"\"\n",
    "    # recipricol of sum of number of items across rows (if axis is 0)\n",
    "    frac = np.array(1.0/(data > 0.0).sum(axis))\n",
    "\n",
    "    # filter any invalid entries\n",
    "    frac[np.ma.masked_invalid(frac).mask] = 0.0\n",
    "\n",
    "    # normalize weights according to assumed distribution of ratings\n",
    "    if wt_type == \"LOG_RATINGS\":\n",
    "        wts = np.array(np.power(frac, feature_wt_exp)).flatten()\n",
    "    else:\n",
    "        wts = np.array(obs_wt * frac).flatten()\n",
    "\n",
    "    # check again for any numerically unstable entries\n",
    "    assert np.isfinite(wts).sum() == wts.shape[0]\n",
    "    return wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rmse(output_row, output_col, actual):\n",
    "    \"\"\"Compute rmse between predicted and actual ratings.\n",
    "      Args:\n",
    "        output_row: evaluated numpy array of row_factor\n",
    "        output_col: evaluated numpy array of col_factor\n",
    "        actual: coo_matrix of actual (test) values\n",
    "      Returns:\n",
    "        rmse\n",
    "      \"\"\"\n",
    "    mse = 0\n",
    "    for i in range(actual.data.shape[0]):\n",
    "        row_pred = output_row[actual.row[i]]\n",
    "        col_pred = output_col[actual.col[i]]\n",
    "        err = actual.data[i] - np.dot(row_pred, col_pred)\n",
    "        mse += err * err\n",
    "    mse /= actual.data.shape[0]\n",
    "    rmse = math.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_build():\n",
    "\tindice = list(zip(tr_sparse.row, tr_sparse.col))\n",
    "\n",
    "\n",
    "\t# In[338]:\n",
    "\n",
    "\n",
    "\t\n",
    "\n",
    "\n",
    "\t# In[348]:\n",
    "\n",
    "\n",
    "\tdim = 34\n",
    "\tnum_iters = 20\n",
    "\treg = 9.83\n",
    "\tunobs = 0.001\n",
    "\twt_type = 1\n",
    "\tfeature_wt_factor =  189.8\n",
    "\tobs_wt = 100\n",
    "\tnum_rows = tr_sparse.shape[0]\n",
    "\tnum_cols = tr_sparse.shape[1]\n",
    "\n",
    "\n",
    "\t# In[341]:\n",
    "\n",
    "\n",
    "\t##Note that data is sparse matrix created by coo_matrix\n",
    "\tinput_tensor = tf.SparseTensor(indices=indice,\n",
    "\t                                values=(tr_sparse.data).astype(np.float32),\n",
    "\t                                dense_shape=tr_sparse.shape)\n",
    "\tassert feature_wt_exp is not None\n",
    "\trow_wts = np.ones(num_rows)\n",
    "\tcol_wts = make_wts(tr_sparse, \"LINEAR_RATINGS\", feature_wt_factor , None, 0)\n",
    "\n",
    "\n",
    "\t# In[342]:\n",
    "\n",
    "\n",
    "\tmodel =  tf.contrib.factorization.WALSModel(num_rows, num_cols, dim,\n",
    "\t                                    unobserved_weight=unobs,\n",
    "\t                                    regularization=reg,\n",
    "\t                                    row_weights=row_wts,\n",
    "\t                                    col_weights=col_wts)\n",
    "\n",
    "\n",
    "\t# In[343]:\n",
    "\n",
    "\n",
    "\t# retrieve the row and column factors\n",
    "\trow_factor = model.row_factors[0]\n",
    "\tcol_factor = model.col_factors[0]\n",
    "\n",
    "\n",
    "\t# In[349]:\n",
    "\n",
    "\n",
    "\trow_update_op = model.update_row_factors(sp_input=input_tensor)[1]\n",
    "\tcol_update_op = model.update_col_factors(sp_input=input_tensor)[1]\n",
    "\tsess = tf.Session(graph=input_tensor.graph)\n",
    "\tsess.run(model.initialize_op)\n",
    "\tsess.run(model.worker_init)\n",
    "\tfor _ in range(num_iters):\n",
    "\t    sess.run(model.row_update_prep_gramian_op)\n",
    "\t    sess.run(model.initialize_row_update_op)\n",
    "\t    sess.run(row_update_op)\n",
    "\t    sess.run(model.col_update_prep_gramian_op)\n",
    "\t    sess.run(model.initialize_col_update_op)\n",
    "\t    sess.run(col_update_op)\n",
    "\n",
    "\n",
    "\t# In[350]:\n",
    "\n",
    "\n",
    "\t# evaluate output factor matrices\n",
    "\toutput_row = row_factor.eval(session=sess)\n",
    "\toutput_col = col_factor.eval(session=sess)\n",
    "\tsess.close()\n",
    "\n",
    "\n",
    "\t# In[351]:\n",
    "\n",
    "\n",
    "\t\n",
    "\n",
    "\n",
    "\t# In[352]:\n",
    "\n",
    "\n",
    "\trmse = get_rmse(output_row, output_col, te_sparse)\n",
    "\treturn rmse;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
