{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Project 2 - Recommender Systems - Surprise Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from surprise import *\n",
    "from surprise.model_selection import PredefinedKFold\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "from implementations import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"data_train.csv\"\n",
    "submission_file = \"sampleSubmission.csv\"\n",
    "\n",
    "trainset, testset, df, toBeSubmitted = load_data(train_file, submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearchDic = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algtype = SVD\n",
    "param_grid = {'n_epochs': [200],\n",
    "              'lr_all': [0.01, 0.0005, 0.001, 0.01, 0.1],\n",
    "              'reg_all':[0.01, 0.0005, 0.001, 0.01, 0.1],\n",
    "             }\n",
    "gs = tuneHyperParams(algtype, trainset, testset, df, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearchDic[\"SVD\"] = gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KnnBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "algotype = KNNBaseline\n",
    "param_grid = {'k': [50, 150, 300], 'n_epochs': [200],'name': ['pearson_baseline'], 'user_based': [True, False]}\n",
    "\n",
    "gs = tuneHyperParams(algotype, trainset, testset, df, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearchDic[\"KnnBaseline\"] = gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SupriseGridSearchDic.pkl', 'wb') as f:\n",
    "    pickle.dump(gridSearchDic, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SlopeOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SlopeOne()\n",
    "# Fit\n",
    "model = algo.fit(trainset)\n",
    "# Predict\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SlopeOne on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0010  0.9997  0.9995  1.0005  1.0005  1.0002  0.0006  \n",
      "Fit time          4.47    4.78    4.79    5.22    4.91    4.83    0.24    \n",
      "Test time         20.56   19.79   19.88   21.16   19.84   20.25   0.54    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.0009662 , 0.99966161, 0.9994735 , 1.00049767, 1.00045951]),\n",
       " 'fit_time': (4.473947048187256,\n",
       "  4.776485443115234,\n",
       "  4.785937309265137,\n",
       "  5.222400188446045,\n",
       "  4.909484624862671),\n",
       " 'test_time': (20.55575442314148,\n",
       "  19.792408227920532,\n",
       "  19.882184267044067,\n",
       "  21.15937352180481,\n",
       "  19.839527368545532)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SlopeOne()\n",
    "\n",
    "d = Dataset.load_from_df(df[['User', 'Movie', 'Rating']], reader)\n",
    "cross_validate(algo, d, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9985  0.9989  0.9995  1.0000  0.9999  0.9993  0.0006  \n",
      "Fit time          6.08    6.97    6.89    6.90    6.82    6.73    0.33    \n",
      "Test time         2.25    2.19    2.17    3.80    2.15    2.51    0.64    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.9985382 , 0.99890149, 0.9994558 , 0.99998731, 0.99986172]),\n",
       " 'fit_time': (6.076967716217041,\n",
       "  6.968732833862305,\n",
       "  6.885484933853149,\n",
       "  6.9013590812683105,\n",
       "  6.822945594787598),\n",
       " 'test_time': (2.252380847930908,\n",
       "  2.194763660430908,\n",
       "  2.1709909439086914,\n",
       "  3.799363136291504,\n",
       "  2.1486735343933105)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BaselineOnly\n",
    "algo = BaselineOnly()\n",
    "bsl_options = {'n_epochs': 20}\n",
    "\n",
    "d = Dataset.load_from_df(df[['User', 'Movie', 'Rating']], reader)\n",
    "cross_validate(algo, d, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Algorithm\n",
    "#algo = SVDpp(n_epochs=30,lr_all=0.001,reg_all=0.001)\n",
    "algtype = SVD\n",
    "param_grid = {'n_epochs': [50],\n",
    "              'lr_all': [0.01, 0.0005, 0.001, 0.01, 0.1],\n",
    "              'reg_all':[0.01, 0.0005, 0.001, 0.01, 0.1],\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Hyperparameters via Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0317596993526121\n",
      "{'n_epochs': 4}\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['User', 'Movie', 'Rating']], reader)\n",
    "#trainset, testset = train_test_split(data, test_size=.25, random_state=20)\n",
    "\n",
    "\n",
    "gs = GridSearchCV(algtype, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
    "\n",
    "model = gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "#algo = SVD(n_factors=factor ,n_epochs=epoch, lr_all=lr_rate, reg_all=reg_rate)\n",
    "algo = gs.best_estimator['rmse']\n",
    "\n",
    "model = algo.fit(trainset)\n",
    "\n",
    "# Predict\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Submission file\n",
    "create_submission_file('submission_surprise', algo, predictions, toBeSubmitted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
